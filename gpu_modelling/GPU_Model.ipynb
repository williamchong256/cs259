{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iExKrgMZtLKE"
      },
      "source": [
        "import math"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gRGJ_l7QMOC"
      },
      "source": [
        "# Performance Modelling for CUDNN on Titan V for GEMM Workloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViER1vImiMIl"
      },
      "source": [
        "## Layer Class Definitions\n",
        "First, let's define a few classes for convenience. Since we're focusing on modeling Convolutional and Gemm layers, we'll define a class for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ4fTVxBsmib"
      },
      "source": [
        "# The ConvLayer represents a convolution with the following parameters:\n",
        "#     The input consists of Ni input channels each of which consist of Ny x Nx images. The shape should be (Ni, Nx, Ny)\n",
        "#     One convolution filter has dimensions Kx x Ky x Ni. The input filter_shape should be (Kx, Ky) and the Ni dimension is assumed.\n",
        "class ConvLayer:\n",
        "  def __init__(self, name, input_shape, filter_shape, num_filters, batch_size = 1, padding = 0, stride = 1):\n",
        "    self.name = name\n",
        "    self.type = \"CONV\"\n",
        "    self.input_shape = input_shape      #(Ni, Nx, Ny)\n",
        "    self.filter_shape = filter_shape    #(Kx, Ky)\n",
        "    self.stride = stride\n",
        "    self.batch_size = batch_size\n",
        "    self.padding = padding\n",
        "    self.num_filters = num_filters\n",
        "\n",
        "# The GemmLayer represents a 2D matrix multiply\n",
        "#     The first matrix has dimensions m x k and the second matrix has dimensions k x n.\n",
        "#     This gives an output with dimensions m x n.\n",
        "class GemmLayer:\n",
        "  def __init__(self, name, m, k, n, batch_size = 1):\n",
        "    self.name = name\n",
        "    self.type = \"GEMM\"\n",
        "    self.m = m\n",
        "    self.k = k\n",
        "    self.n = n\n",
        "    self.batch_size = batch_size"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me_-qacNiklj"
      },
      "source": [
        "## Titan V Parameters, Constants, and Test Model Parameters\n",
        "\n",
        "- Defined here are some performance and hardware stats for the Titan V GPU\n",
        "- We also define several NN models from sequences of convolutional/GEMM layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOJXw3uBPiO"
      },
      "source": [
        "# Define parameters or lists of parameters here\n",
        "\n",
        "#============================================\n",
        "# From https://www.anandtech.com/show/12673/titan-v-deep-learning-deep-dive and https://www.nvidia.com/en-us/titan/titan-v/\n",
        "# Parameters from NVIDIA Titan V\n",
        "num_CUDA_Cores = 5120     # Total number of CUDA cores\n",
        "num_Tensor_Cores = 640    # Tensor Cores, Hopefully not used\n",
        "num_ROPs = 96             # Render Output Units, Hopefully not used\n",
        "num_Streaming_Multiprocessors = 80    # This is different from the number in the slides.\n",
        "\n",
        "Core_Clock = 1200000000             # 1200MHz\n",
        "Boost_Clock = 1455000000            # 1455MHz\n",
        "Memory_Clock = 850000000            # 850MHz\n",
        "Memory_Data_Rate = 1825361101           # 1.7Gbps HBM2 (bits per second not bytes)\n",
        "\n",
        "Memory_Bus_Width = 3072             # 3072 bits\n",
        "Memory_Bandwidth = 701153411072     # 653GB/sec in Bytes\n",
        "\n",
        "# bandwidth from L2 to L1\n",
        "# calculated by numbers in table 2 of this link: https://arxiv.org/pdf/1810.07269.pdf\n",
        "# L2 to L1 has 128B line, 32 ways\n",
        "# 128 byte 32 lines = 4096 bytes/cycle\n",
        "# 4096 bytes/cycle * Boost_Clock = 5.96e12 Bytes/sec  \n",
        "L2_to_L1_Bandwidth = 5.96e12     # 5.9 TB/sec\n",
        "\n",
        "VRAM_size = 12000000000             # 12GB\n",
        "L2_size = 4500000                   # 4.5MB\n",
        "Shared_Memory_Size = 98304          # 96KB\n",
        "\n",
        "Single_Precision_Performance = 13800000000000   # 13.8 TFLOPS\n",
        "Double_Precision_Performance =  6900000000000   # 6.9 TFLOPS\n",
        "Half_Precision_Performance =   27600000000000   # 27.6 TFLOPS\n",
        "Integer_INT8_Performance =     55200000000000   # 55.2 TOPS\n",
        "Tensor_Performance =          110000000000000   # 110 TFLOPS\n",
        "\n",
        "# Memory access latency values:\n",
        "# source: https://arxiv.org/pdf/1810.07269.pdf\n",
        "# https://arxiv.org/pdf/1804.06826.pdf\n",
        "L1_latency = 19   #cycles, instead of 28 from the first link, 19 from second for shared latency\n",
        "L2_latency = 198  #cycles, from second link\n",
        "VRAM_latency = 100 #nanoseconds\n",
        "\n",
        "# Main memory bandwidth, commented out to check\n",
        "main_memory_bandwidth = 126e9 #15754000000 # 15.754 GB/sec in Bytes (decimal)\n",
        "\n",
        "\n",
        "# ran an empty/arbitrary kernel on the TitanV and took the minimum execution time with nvprof\n",
        "STARTUP_TIME = 1.216e-6      # seconds\n",
        "\n",
        "#============================================\n",
        "\n",
        "# We are making the following simplifying assumptions:\n",
        "\n",
        "#   - We are assuming always using the boost clock\n",
        "#   - Since we don't know which clock was used to computer performance numbers, we are basing CPOP of info from https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?fbclid=IwAR3_uznGWPcbbWDJMv2Gsa1VgqOCpfrBMoK7yJdhrIvvjz7DumnH4XDzlbY#arithmetic-instructions\n",
        "# def compute_CPOP(): #precision):\n",
        "#   #TODO: Finish\n",
        "#   return 1\n",
        "# number_of_cycles_per_op = compute_CPOP()\n",
        "\n",
        "# The layer specifications we tested in Mini-Project 1 are as follows:\n",
        "# Conv1: Nx=224 Ny=224 Kx=3 Ky=3 Ni=64 Nn=64\n",
        "# Conv2: Nx=14 Ny=14 Kx=3 Ky=3 Ni=512 Nn=512\n",
        "# Class1: Ni=25088 Nn=4096\n",
        "# Class2: Ni=4096 Nn=1024\n",
        "\n",
        "# The \"precision\" variable can have one of the following string values:\n",
        "# \"FP16\" - Half precision 16-bit floating point\n",
        "# \"FP32\" - Single precision 32-bit floating point\n",
        "# \"FP64\" - Double precision 64-bit floating point\n",
        "# \"INT8\" - 8-bit integer\n",
        "def verifyPrecisionValue(precision):\n",
        "  if (precision != \"FP16\" and precision != \"FP32\" and precision != \"FP64\" and precision != \"INT8\"):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "#============================================\n",
        "# Input Parameters Here\n",
        "conv_layers = []\n",
        "\n",
        "# Conv1 layers with multiple batch sizes.\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b1\", (64,224,224), (3,3), 64, 1))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b2\", (64,224,224), (3,3), 64, 2))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b4\", (64,224,224), (3,3), 64, 4))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b8\", (64,224,224), (3,3), 64, 8))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b16\", (64,224,224), (3,3), 64, 16))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b32\", (64,224,224), (3,3), 64, 32))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b64\", (64,224,224), (3,3), 64, 64))\n",
        "conv_layers.append(ConvLayer(\"Conv_1_b128\", (64,224,224), (3,3), 64, 128))\n",
        "\n",
        "# Conv2 layers with multiple batch sizes.\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b1\", (512,14,14), (3,3), 512, 1))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b2\", (512,14,14), (3,3), 512, 2))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b4\", (512,14,14), (3,3), 512, 4))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b8\", (512,14,14), (3,3), 512, 8))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b16\", (512,14,14), (3,3), 512, 16))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b32\", (512,14,14), (3,3), 512, 32))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b64\", (512,14,14), (3,3), 512, 64))\n",
        "conv_layers.append(ConvLayer(\"Conv_2_b128\", (512,14,14), (3,3), 512, 128))\n",
        "\n",
        "gemm_layers = []\n",
        "# Note: The following specs are not for FC layers.\n",
        "# FC layers use a series of dot products, not a full matrix multiply.\n",
        "# Using Gemm with im2col can be used to compute convolution layers.\n",
        "gemm_layers.append(GemmLayer(\"Gemm_0\", 25088, 25088, 4096, 1))\n",
        "gemm_layers.append(GemmLayer(\"Gemm_1\", 4096, 4096, 1024, 1))\n",
        "#============================================"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fngOZ3cjBkv"
      },
      "source": [
        "## Functions to help calculate execution time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDpFS0tyoePz"
      },
      "source": [
        "# assume a slightly higher-end computer setup\n",
        "# DRAM clocked at 3600 MHz, CAS 16 latency, which has first word latency of 8.89 ns\n",
        "# know that Titan V interfaces with PCIe 3.0x16, so 32 GB/s; \n",
        "# PCIe 3.0 bus latency - https://www.dolphinics.com/download/WHITEPAPERS/Dolphinproductbrochure.pdf\n",
        "# approximately 500 ns\n",
        "def latency_of(source, clock_rate):\n",
        "  \"\"\"\n",
        "  :param source: string denoting whether we're leaving L1/shared, L2, or VRAM\n",
        "  :return: float value for latency penalty\n",
        "  \"\"\"\n",
        "  if source in (\"L1\", \"shared\"):\n",
        "    return L1_latency / clock_rate\n",
        "  elif source == \"L2\":\n",
        "    return L2_latency / clock_rate\n",
        "  elif source == \"VRAM\":\n",
        "    return VRAM_latency\n",
        "  else:\n",
        "    # copying from CPU DRAM to GPU VRAM\n",
        "    return 5e-7 + 8.89e-9"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtVGHCmEXiSK"
      },
      "source": [
        "# time to load FROM main memory (CPU) TO GPU VRAM\n",
        "def time_to_load_from_main_memory(precision, size_data):\n",
        "  load_time = 0\n",
        "  if precision == \"FP16\":\n",
        "    load_time = size_data*2/main_memory_bandwidth + latency_of(\"main\", Boost_Clock)\n",
        "  elif precision == \"FP32\":\n",
        "    load_time = size_data*4/main_memory_bandwidth + latency_of(\"main\", Boost_Clock)\n",
        "  elif precision == \"FP64\":\n",
        "    load_time = size_data*8/main_memory_bandwidth + latency_of(\"main\", Boost_Clock)\n",
        "  elif precision == \"INT8\":\n",
        "    load_time = size_data*1/main_memory_bandwidth + latency_of(\"main\", Boost_Clock)\n",
        "  else:\n",
        "    print(\"ERROR: Invalid precision\")\n",
        "  return load_time\n",
        "\n",
        "# time to load FROM VRAM to L2\n",
        "def time_to_load_from_VRAM(precision, size_data): \n",
        "  load_time = 0\n",
        "  if precision == \"FP16\":\n",
        "    load_time = size_data*2/Memory_Bandwidth + latency_of(\"VRAM\", Boost_Clock)\n",
        "  elif precision == \"FP32\":\n",
        "    load_time = size_data*4/Memory_Bandwidth + latency_of(\"VRAM\", Boost_Clock)\n",
        "  elif precision == \"FP64\":\n",
        "    load_time = size_data*8/Memory_Bandwidth + latency_of(\"VRAM\", Boost_Clock)\n",
        "  elif precision == \"INT8\":\n",
        "    load_time = size_data*1/Memory_Bandwidth + latency_of(\"VRAM\", Boost_Clock)\n",
        "  else:\n",
        "    print(\"ERROR: Invalid precision\")\n",
        "  return load_time\n",
        "\n",
        "# time to load from L2 to L1 WITHOUT latency penalty\n",
        "# this is different from the following function, and will be used to help compute tiling memory costs\n",
        "def time_to_load_from_L2_to_L1(precision, size_data):\n",
        "  load_time = 0\n",
        "  if precision == \"FP16\":\n",
        "    load_time = size_data*2/L2_to_L1_Bandwidth \n",
        "  elif precision == \"FP32\":\n",
        "    load_time = size_data*4/L2_to_L1_Bandwidth \n",
        "  elif precision == \"FP64\":\n",
        "    load_time = size_data*8/L2_to_L1_Bandwidth \n",
        "  elif precision == \"INT8\":\n",
        "    load_time = size_data*1/L2_to_L1_Bandwidth \n",
        "  else:\n",
        "    print(\"ERROR: Invalid precision\")\n",
        "  return load_time\n",
        "\n",
        "# time to load FROM L2 TO L1\n",
        "def time_to_load_from_device_memory(precision, size_data): #size_data is given in terms of values, not taking precision into account.\n",
        "  load_time = 0\n",
        "  if precision == \"FP16\":\n",
        "    load_time = size_data*2/L2_to_L1_Bandwidth + latency_of(\"L2\", Boost_Clock)\n",
        "  elif precision == \"FP32\":\n",
        "    load_time = size_data*4/L2_to_L1_Bandwidth + latency_of(\"L2\", Boost_Clock)\n",
        "  elif precision == \"FP64\":\n",
        "    load_time = size_data*8/L2_to_L1_Bandwidth + latency_of(\"L2\", Boost_Clock)\n",
        "  elif precision == \"INT8\":\n",
        "    load_time = size_data*1/L2_to_L1_Bandwidth + latency_of(\"L2\", Boost_Clock)\n",
        "  else:\n",
        "    print(\"ERROR: Invalid precision\")\n",
        "  return load_time\n",
        "\n",
        "# time to load FROM L1/Shared TO kernelexecution/processors\n",
        "# shared memory is same as L1 cache in terms of speed \n",
        "def time_to_load_from_shared_memory(precision, size_data): #size_data is given in terms of values, not taking precision into account.\n",
        "  load_time = 0\n",
        "  if precision == \"FP16\":\n",
        "    load_time = size_data*2/Memory_Bandwidth + latency_of(\"L1\", Boost_Clock)\n",
        "  elif precision == \"FP32\":\n",
        "    load_time = size_data*4/Memory_Bandwidth + latency_of(\"L1\", Boost_Clock)\n",
        "  elif precision == \"FP64\":\n",
        "    load_time = size_data*8/Memory_Bandwidth + latency_of(\"L1\", Boost_Clock)\n",
        "  elif precision == \"INT8\":\n",
        "    load_time = size_data*1/Memory_Bandwidth + latency_of(\"L1\", Boost_Clock)\n",
        "  else:\n",
        "    print(\"ERROR: Invalid precision\")\n",
        "  return load_time\n",
        "  \n",
        "# empirical meaning using the TFLOPs data from cell 2 instead of the NVIDIA CPOP table link\n",
        "def time_to_execute(precision, num_ops, empirical = True): \n",
        "  if not empirical:  # using NVIDIA table link \n",
        "    if precision == \"FP16\":\n",
        "      execution_time = num_ops / (128 * num_Streaming_Multiprocessors * Boost_Clock)  \n",
        "    elif precision == \"FP32\":\n",
        "      execution_time = num_ops / (64 * num_Streaming_Multiprocessors * Boost_Clock)  \n",
        "    elif precision == \"FP64\":\n",
        "      execution_time = num_ops / (32 * num_Streaming_Multiprocessors * Boost_Clock)  \n",
        "    elif precision == \"INT8\":\n",
        "      # not much in documentation on the throughput for INT8 but links such as: \n",
        "      # https://forums.developer.nvidia.com/t/titan-v-white-paper-and-int8-tops/72776\n",
        "      # https://docs.nvidia.com/cuda/pascal-tuning-guide/index.html\n",
        "      # imply that INT8 throughput is 4x that of FP32 \n",
        "      execution_time = num_ops / (4 * 64 * num_Streaming_Multiprocessors * Boost_Clock)  \n",
        "    else:\n",
        "      print(\"ERROR: Invalid precision\")\n",
        "      return -1\n",
        "  else:\n",
        "    if precision == \"FP16\":\n",
        "      execution_time = num_ops / Half_Precision_Performance\n",
        "    elif precision == \"FP32\":\n",
        "      execution_time = num_ops / Single_Precision_Performance\n",
        "    elif precision == \"FP64\":\n",
        "      execution_time = num_ops / Double_Precision_Performance\n",
        "    elif precision == \"INT8\":\n",
        "      execution_time = num_ops / Integer_INT8_Performance\n",
        "    else:\n",
        "      print(\"ERROR: Invalid precision\")\n",
        "      return -1\n",
        "  return execution_time"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1YFIZml2dmc"
      },
      "source": [
        "# In the project spec, the professor mentioned finding the max time of each of compute, memory, and buffer bandwidths.\n",
        "# We are supposed to be better than this, but this seems doable.\n",
        "\n",
        "\n",
        "def find_compute_bound_time(precision, layer_shape, empirical = True):\n",
        "  '''\n",
        "  :param precision: which precision type, FP16, FP32, ...\n",
        "  :type precision: string\n",
        "  :param layer_shape: a Layer object denoting layer properties\n",
        "  :type layer_shape: Layer\n",
        "  :param empirical: choose whether to use \"empirical\" data from cell 2 or \"ideal\" from table linked\n",
        "  :type empirical: bool\n",
        "\n",
        "  :return: float denoting expected compute time in seconds\n",
        "\n",
        "  '''\n",
        "  # Based on Number of Operations\n",
        "  expected_time = 0\n",
        "  if (layer_shape.type == \"GEMM\"):\n",
        "    num_mults = layer_shape.m * layer_shape.k * layer_shape.n\n",
        "    num_adds = layer_shape.m * (layer_shape.k - 1) * layer_shape.n\n",
        "    total_ops = num_mults + num_adds\n",
        "    expected_time = time_to_execute(precision, total_ops, empirical)\n",
        "\n",
        "  elif (layer_shape.type == \"CONV\"):\n",
        "    # Number of dot product ops:  ((nx -kx + 2P)/S + 1) * ((ny - ky + 2P)/S + 1) * Nn \n",
        "    # number of multiply and add ops per stride: (kx * ky * Ni) multiplies and (kx * ky * Ni - 1) adds\n",
        "    num_dot_prods = (math.floor((layer_shape.input_shape[1] - layer_shape.filter_shape[0] + 2*layer_shape.padding) / layer_shape.stride) + 1) \\\n",
        "                        * (math.floor((layer_shape.input_shape[2] - layer_shape.filter_shape[1] + 2*layer_shape.padding) / layer_shape.stride) + 1) \\\n",
        "                        * layer_shape.num_filters\n",
        "    num_ops_per_dot = 2 * (layer_shape.filter_shape[0] * layer_shape.filter_shape[1] * layer_shape.input_shape[0])\n",
        "    total_ops = num_dot_prods * num_ops_per_dot * layer_shape.batch_size\n",
        "    expected_time = time_to_execute(precision, total_ops, empirical)\n",
        "  expected_time = expected_time\n",
        "  return expected_time\n",
        "\n",
        "# #test code\n",
        "# compute_bound_time = find_compute_bound_time(\"FP16\", ConvLayer(\"Conv_1\", (64,224,224),(3,3), 1, 0, 1), False)\n",
        "# print(\"Table: \" + str(compute_bound_time) + \" seconds\")\n",
        "# compute_bound_time = find_compute_bound_time(\"FP16\", ConvLayer(\"Conv_1\", (64,224,224),(3,3), 1, 0, 1), True)\n",
        "# print(\"Empirical: \" + str(compute_bound_time) + \" seconds\")\n",
        "\n",
        "\n",
        "def find_memory_bound_time(precision,layer_shape):\n",
        "  # From Host\n",
        "  expected_time = 0\n",
        "  if (layer_shape.type == \"GEMM\"):\n",
        "    # This is the bare minimum assuming each value is loaded exactly once.\n",
        "    size_load_data = layer_shape.k * (layer_shape.m + layer_shape.n * layer_shape.batch_size)\n",
        "    size_out_data = layer_shape.m * layer_shape.n * layer_shape.batch_size\n",
        "  elif (layer_shape.type == \"CONV\"):\n",
        "    # This is the bare minimum assuming each value is loaded exactly once.\n",
        "    size_load_data = layer_shape.input_shape[0]*(layer_shape.input_shape[1]*layer_shape.input_shape[2]*layer_shape.batch_size + layer_shape.num_filters*layer_shape.filter_shape[0]*layer_shape.filter_shape[1])\n",
        "    size_out_data = layer_shape.num_filters*(layer_shape.input_shape[1]-layer_shape.filter_shape[0]+1)*(layer_shape.input_shape[2]-layer_shape.filter_shape[1]+1)*layer_shape.batch_size\n",
        "  print(\"Data size is load \"+str(size_load_data)+\" and output \"+str(size_out_data))\n",
        "  expected_time = time_to_load_from_main_memory(precision,size_load_data+size_out_data)\n",
        "  return expected_time\n",
        "\n",
        "def find_buffer_bandwidth_bound_time(precision,layer_shape):\n",
        "  # DRAM Staging Buffer Bandwidth on Device\n",
        "  expected_time = 0\n",
        "  if (layer_shape.type == \"GEMM\"):\n",
        "    # This is the bare minimum assuming each value is loaded exactly once.\n",
        "    size_load_data = layer_shape.k * (layer_shape.m + layer_shape.n * layer_shape.batch_size)\n",
        "    size_out_data = layer_shape.m * layer_shape.n * layer_shape.batch_size\n",
        "  elif (layer_shape.type == \"CONV\"):\n",
        "    # This is the bare minimum assuming each value is loaded exactly once.\n",
        "    size_load_data = layer_shape.input_shape[0]*(layer_shape.input_shape[1]*layer_shape.input_shape[2]*layer_shape.batch_size + layer_shape.num_filters*layer_shape.filter_shape[0]*layer_shape.filter_shape[1])\n",
        "    size_out_data = layer_shape.num_filters*(layer_shape.input_shape[1]-layer_shape.filter_shape[0]+1)*(layer_shape.input_shape[2]-layer_shape.filter_shape[1]+1)*layer_shape.batch_size\n",
        "  print(\"Data size is load \"+str(size_load_data)+\" and output \"+str(size_out_data))\n",
        "  expected_time = time_to_load_from_L2_to_L1(precision,size_load_data+size_out_data)\n",
        "  return expected_time"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu1HUWKJjeBm"
      },
      "source": [
        "## Roofline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-byK8DSnowu"
      },
      "source": [
        "def roofline_model(precision,layer_shape):\n",
        "  \"\"\" \n",
        "  Returns a tuple of format(execution_time, [compute, memory, buffer])\n",
        "  \"\"\"\n",
        "  execution_time = 0\n",
        "\n",
        "  compute_bound_time = find_compute_bound_time(precision,layer_shape)\n",
        "  print(\"Compute: \"+str(compute_bound_time))\n",
        "  memory_bound_time = find_memory_bound_time(precision,layer_shape)\n",
        "  print(\"Memory: \"+str(memory_bound_time))\n",
        "  buffer_bound_time = find_buffer_bandwidth_bound_time(precision,layer_shape)\n",
        "  print(\"Buffer: \"+str(buffer_bound_time))\n",
        "\n",
        "  execution_time = compute_bound_time\n",
        "\n",
        "  if (memory_bound_time > execution_time and memory_bound_time > buffer_bound_time):\n",
        "    execution_time = memory_bound_time\n",
        "    return (execution_time, \"memory\")\n",
        "  if (buffer_bound_time > execution_time and buffer_bound_time > memory_bound_time):\n",
        "    execution_time = buffer_bound_time\n",
        "    return (execution_time, \"buffer\")\n",
        "  return (execution_time+STARTUP_TIME, \"compute\")\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpn025cFQ-Qe"
      },
      "source": [
        "def gemm(precision,gemm_layer):   # Roofline Model Baseline\n",
        "  execution_time = 0\n",
        "\n",
        "  # Here is some more filler code\n",
        "\n",
        "  results = roofline_model(precision,gemm_layer)\n",
        "\n",
        "  return results"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8zWmf7UU0hY"
      },
      "source": [
        "def conv(precision,conv_layer):   # Roofline Model Baseline\n",
        "  execution_time = 0\n",
        "\n",
        "  # Here is some more filler code\n",
        "\n",
        "  results = roofline_model(precision,conv_layer)\n",
        "\n",
        "  return results"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6gVMS6C9zup"
      },
      "source": [
        "def im2col(conv_layer):\n",
        "  # im2col is used to convert convolution into a GEMM\n",
        "  # Each convolution is unrolled. For Ni input channels that are Kx x Kn and Nn input filters, this would mean our gemm will be of dimensions (m,k)x(k,n) where m = Nn, k = Ni*Kx*Ky, and n = number_output_values_per_channel.\n",
        "  gemm_layer = GemmLayer(conv_layer.name+\"_gemm\", conv_layer.num_filters, conv_layer.filter_shape[0]*conv_layer.filter_shape[1]*conv_layer.input_shape[0], (conv_layer.input_shape[1]-conv_layer.filter_shape[0]+1)*(conv_layer.input_shape[2]-conv_layer.filter_shape[1]+1), conv_layer.batch_size)\n",
        "  return gemm_layer"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkTEKubeSUI6"
      },
      "source": [
        "def find_tiled_times(precision,gemm_layer):\n",
        "  total_time = 0\n",
        "  tile_dim = 1    #Tiles are assumed to be square.\n",
        "  row_col_size = gemm_layer.k\n",
        "\n",
        "  if precision == \"FP16\":\n",
        "    precision_multiplier  = 2\n",
        "  elif precision == \"FP32\":\n",
        "    precision_multiplier = 4\n",
        "  elif precision == \"FP64\":\n",
        "    precision_multiplier = 8\n",
        "  else: #\"INT8\"\n",
        "    precision_multiplier = 1\n",
        "\n",
        "  total_size = (gemm_layer.m*gemm_layer.n+gemm_layer.k*(gemm_layer.m+gemm_layer.n))*precision_multiplier\n",
        "\n",
        "  if (total_size <= Shared_Memory_Size):\n",
        "    bound_str = \"memory\"\n",
        "    memory_bound = find_memory_bound_time(precision, gemm_layer)\n",
        "    total_time = memory_bound\n",
        "    compute_bound = find_compute_bound_time(precision, gemm_layer)\n",
        "    if (compute_bound > total_time):\n",
        "      bound_str = \"compute\"\n",
        "      total_time = compute_bound\n",
        "    buffer_bound = find_buffer_bandwidth_bound_time(precision, gemm_layer)\n",
        "    if (buffer_bound > total_time):\n",
        "      bound_str = \"buffer\"\n",
        "      total_time = buffer_bound\n",
        "  else:\n",
        "    #Find tile size. Start with an overestimate\n",
        "    tile_dim = math.floor(Shared_Memory_Size/(2*row_col_size))   # This ignores the output values, so we need a correction.\n",
        "    tile_size = tile_dim*(tile_dim+2*row_col_size)*precision_multiplier\n",
        "    while tile_size > Shared_Memory_Size:\n",
        "      tile_dim = tile_dim - 1\n",
        "      tile_size = tile_dim*(tile_dim+2*row_col_size)*precision_multiplier\n",
        "\n",
        "    #Iterate through tiles. Note that we assume the tiles iterate along the n dimension first and all weights only need to fully change at the end of each row.\n",
        "    #Number of full tiles:\n",
        "    n_tiles = math.floor(gemm_layer.n/tile_dim)\n",
        "    m_tiles = math.floor(gemm_layer.m/tile_dim)\n",
        "    buffer_bound = time_to_load_from_L2_to_L1(precision,tile_size*n_tiles*m_tiles+row_col_size*n_tiles*(m_tiles+1)*precision_multiplier)\n",
        "    #Partial tiles. These tiles will require less loaded memory and fewer operations to execute.\n",
        "    leftover_n = gemm_layer.n - tile_dim*n_tiles\n",
        "    leftover_m = gemm_layer.m - tile_dim*m_tiles\n",
        "    buffer_bound = buffer_bound + time_to_load_from_L2_to_L1(precision,(leftover_m+(leftover_n*row_col_size)*(m_tiles))*precision_multiplier)\n",
        "    # Add Compute Bound Time\n",
        "    compute_bound = find_compute_bound_time(precision, gemm_layer)\n",
        "    memory_bound = find_memory_bound_time(precision, gemm_layer)\n",
        "    total_time = buffer_bound*gemm_layer.batch_size\n",
        "    bound_str = \"buffer\"\n",
        "    if (memory_bound > total_time):\n",
        "      bound_str = \"memory\"\n",
        "      total_time = memory_bound\n",
        "    if (compute_bound > total_time):\n",
        "      bound_str = \"compute\"\n",
        "      total_time = compute_bound\n",
        "\n",
        "  return (total_time+STARTUP_TIME, bound_str)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvyAfhkGjqb8"
      },
      "source": [
        "## Test Driver Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp_FqY1rU6T7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803c5b12-1a4a-47e9-cdd1-7202e3813452"
      },
      "source": [
        "precision = \"FP16\"\n",
        "\n",
        "if verifyPrecisionValue(precision):\n",
        "  # # Loop through parameters and layer sizes for gemm here\n",
        "  # print(\"===============\")\n",
        "  # print(\"GEMM Results\")\n",
        "  # print(f\"===============\\n\")\n",
        "  # total = 0\n",
        "  # for i in range(len(gemm_layers)):  # Placeholder loop\n",
        "  #   res = gemm(precision,gemm_layers[i])\n",
        "  #   total += res[0]\n",
        "  #   print(gemm_layers[i].name + \" Execution Time: \" + str(res[0]) + \"\\n\\tbounded by: \" + res[1]+ \"\\n\")\n",
        "\n",
        "  # print(\"\\nTotal execution time: {}\".format(total))\n",
        "\n",
        "  # print(\"===============\")\n",
        "  # print(f\"===============\\n\\n\\n\")\n",
        "\n",
        "  # Loop through parameters and layer sizes for conv here\n",
        "  print(\"===============\")\n",
        "  print(\"Conv Results\")\n",
        "  print(f\"===============\\n\")\n",
        "  total = 0\n",
        "  for i in range(len(conv_layers)):  # Placeholder loop\n",
        "    res = conv(precision,conv_layers[i])\n",
        "    total += res[0]\n",
        "    print(conv_layers[i].name + \" Execution Time: \" + str(res[0]) + \"\\n\\tbounded by: \" + res[1] + \"\\n\")\n",
        "\n",
        "  print(\"\\nTotal execution time: {}\".format(total))\n",
        "\n",
        "  print(\"===============\")\n",
        "  print(f\"===============\\n\\n\\n\")\n",
        "  \n",
        "  print(\"===============\")\n",
        "  print(\"im2col Results for Conv as GEMM\")\n",
        "  print(f\"===============\\n\")\n",
        "  total = 0\n",
        "  for i in range(len(conv_layers)):  # Placeholder loop\n",
        "    im2col_layer = im2col(conv_layers[i])\n",
        "    res = find_tiled_times(precision,im2col_layer)\n",
        "    total += res[0]\n",
        "    print(im2col_layer.name + \" Execution Time: \" + str(res[0]) + \"\\n\\tbounded by: \" + res[1] + \"\\n\")\n",
        "\n",
        "  print(\"\\nTotal execution time: {}\".format(total))\n",
        "\n",
        "  print(\"===============\")\n",
        "  print(\"===============\")\n",
        "else:\n",
        "  print(\"Incorrect precision value: \"+precision+\" please enter a string from the following list: FP16, FP32, FP64, INT8\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============\n",
            "Conv Results\n",
            "===============\n",
            "\n",
            "Compute: 0.00013165256347826086\n",
            "Data size is load 3248128 and output 3154176\n",
            "Memory: 0.00010213276301587301\n",
            "Data size is load 3248128 and output 3154176\n",
            "Buffer: 2.1484241610738256e-06\n",
            "Conv_1_b1 Execution Time: 0.00013286856347826087\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.0002633051269565217\n",
            "Data size is load 6459392 and output 6308352\n",
            "Memory: 0.00020317149317460316\n",
            "Data size is load 6459392 and output 6308352\n",
            "Buffer: 4.284477852348994e-06\n",
            "Conv_1_b2 Execution Time: 0.0002645211269565217\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.0005266102539130434\n",
            "Data size is load 12881920 and output 12616704\n",
            "Memory: 0.0004052489534920635\n",
            "Data size is load 12881920 and output 12616704\n",
            "Buffer: 8.556585234899329e-06\n",
            "Conv_1_b4 Execution Time: 0.0005278262539130434\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.0010532205078260868\n",
            "Data size is load 25726976 and output 25233408\n",
            "Memory: 0.0008094038741269841\n",
            "Data size is load 25726976 and output 25233408\n",
            "Buffer: 1.71008e-05\n",
            "Conv_1_b8 Execution Time: 0.001054436507826087\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.0021064410156521737\n",
            "Data size is load 51417088 and output 50466816\n",
            "Memory: 0.0016177137153968256\n",
            "Data size is load 51417088 and output 50466816\n",
            "Buffer: 3.4189229530201345e-05\n",
            "Conv_1_b16 Execution Time: 0.0021076570156521738\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.004212882031304347\n",
            "Data size is load 102797312 and output 100933632\n",
            "Memory: 0.0032343333979365082\n",
            "Data size is load 102797312 and output 100933632\n",
            "Buffer: 6.836608859060403e-05\n",
            "Conv_1_b32 Execution Time: 0.0042140980313043475\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.008425764062608695\n",
            "Data size is load 205557760 and output 201867264\n",
            "Memory: 0.006467572763015872\n",
            "Data size is load 205557760 and output 201867264\n",
            "Buffer: 0.0001367198067114094\n",
            "Conv_1_b64 Execution Time: 0.008426980062608695\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.01685152812521739\n",
            "Data size is load 411078656 and output 403734528\n",
            "Memory: 0.012934051493174604\n",
            "Data size is load 411078656 and output 403734528\n",
            "Buffer: 0.00027342724295302014\n",
            "Conv_1_b128 Execution Time: 0.016852744125217388\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 2.4618740869565218e-05\n",
            "Data size is load 2459648 and output 73728\n",
            "Memory: 4.072120746031746e-05\n",
            "Data size is load 2459648 and output 73728\n",
            "Buffer: 8.501261744966443e-07\n",
            "Conv_2_b1 Execution Time: 4.072120746031746e-05\n",
            "\tbounded by: memory\n",
            "\n",
            "Compute: 4.9237481739130435e-05\n",
            "Data size is load 2560000 and output 147456\n",
            "Memory: 4.348438206349206e-05\n",
            "Data size is load 2560000 and output 147456\n",
            "Buffer: 9.085422818791946e-07\n",
            "Conv_2_b2 Execution Time: 5.045348173913044e-05\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 9.847496347826087e-05\n",
            "Data size is load 2760704 and output 294912\n",
            "Memory: 4.9010731269841264e-05\n",
            "Data size is load 2760704 and output 294912\n",
            "Buffer: 1.0253744966442954e-06\n",
            "Conv_2_b4 Execution Time: 9.969096347826087e-05\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.00019694992695652174\n",
            "Data size is load 3162112 and output 589824\n",
            "Memory: 6.006342968253968e-05\n",
            "Data size is load 3162112 and output 589824\n",
            "Buffer: 1.2590389261744967e-06\n",
            "Conv_2_b8 Execution Time: 0.00019816592695652175\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.0003938998539130435\n",
            "Data size is load 3964928 and output 1179648\n",
            "Memory: 8.21688265079365e-05\n",
            "Data size is load 3964928 and output 1179648\n",
            "Buffer: 1.7263677852348994e-06\n",
            "Conv_2_b16 Execution Time: 0.0003951158539130435\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.000787799707826087\n",
            "Data size is load 5570560 and output 2359296\n",
            "Memory: 0.00012637962015873015\n",
            "Data size is load 5570560 and output 2359296\n",
            "Buffer: 2.6610255033557046e-06\n",
            "Conv_2_b32 Execution Time: 0.0007890157078260869\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.001575599415652174\n",
            "Data size is load 8781824 and output 4718592\n",
            "Memory: 0.00021480120746031746\n",
            "Data size is load 8781824 and output 4718592\n",
            "Buffer: 4.530340939597316e-06\n",
            "Conv_2_b64 Execution Time: 0.001576815415652174\n",
            "\tbounded by: compute\n",
            "\n",
            "Compute: 0.003151198831304348\n",
            "Data size is load 15204352 and output 9437184\n",
            "Memory: 0.0003916443820634921\n",
            "Data size is load 15204352 and output 9437184\n",
            "Buffer: 8.268971812080536e-06\n",
            "Conv_2_b128 Execution Time: 0.003152414831304348\n",
            "\tbounded by: compute\n",
            "\n",
            "\n",
            "Total execution time: 0.03988352507528641\n",
            "===============\n",
            "===============\n",
            "\n",
            "\n",
            "\n",
            "===============\n",
            "im2col Results for Conv as GEMM\n",
            "===============\n",
            "\n",
            "Data size is load 28424448 and output 3154176\n",
            "Conv_1_b1_gemm Execution Time: 0.00050297289\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 56812032 and output 6308352\n",
            "Conv_1_b2_gemm Execution Time: 0.0010036357471428572\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 113587200 and output 12616704\n",
            "Conv_1_b4_gemm Execution Time: 0.0020049614614285716\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 227137536 and output 25233408\n",
            "Conv_1_b8_gemm Execution Time: 0.00400761289\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 454238208 and output 50466816\n",
            "Conv_1_b16_gemm Execution Time: 0.008012915747142857\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 908439552 and output 100933632\n",
            "Conv_1_b32_gemm Execution Time: 0.01602352146142857\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 1816842240 and output 201867264\n",
            "Conv_1_b64_gemm Execution Time: 0.03204473289\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 3633647616 and output 403734528\n",
            "Conv_1_b128_gemm Execution Time: 0.06408715574714285\n",
            "\tbounded by: memory\n",
            "\n",
            "Data size is load 3022848 and output 73728\n",
            "Conv_2_b1_gemm Execution Time: 9.976997181208053e-05\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 3686400 and output 147456\n",
            "Conv_2_b2_gemm Execution Time: 0.00019832394362416107\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 5013504 and output 294912\n",
            "Conv_2_b4_gemm Execution Time: 0.00039543188724832214\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 7667712 and output 589824\n",
            "Conv_2_b8_gemm Execution Time: 0.0007896477744966442\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 12976128 and output 1179648\n",
            "Conv_2_b16_gemm Execution Time: 0.0015780795489932886\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 23592960 and output 2359296\n",
            "Conv_2_b32_gemm Execution Time: 0.003154943097986577\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 44826624 and output 4718592\n",
            "Conv_2_b64_gemm Execution Time: 0.006308670195973154\n",
            "\tbounded by: buffer\n",
            "\n",
            "Data size is load 87293952 and output 9437184\n",
            "Conv_2_b128_gemm Execution Time: 0.012616124391946308\n",
            "\tbounded by: buffer\n",
            "\n",
            "\n",
            "Total execution time: 0.15282849964636622\n",
            "===============\n",
            "===============\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}